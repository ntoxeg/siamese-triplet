epoch,train_loss,valid_loss,time
0,62.107155,0.874153,21:22
1,16.554363,0.265149,21:23
2,0.605220,0.153371,21:21
3,0.131938,0.144664,21:27
4,0.126519,0.121650,21:29
5,0.110965,0.104312,21:22
6,0.101370,0.092600,21:28
7,0.099828,0.087849,21:24
8,0.094340,0.091380,21:23
9,0.096288,0.083496,21:24
10,0.095519,0.081799,21:25
11,0.091567,0.082531,21:31
12,0.090482,0.084675,21:26
13,0.092851,0.082043,21:28
14,0.095104,0.083551,21:26
15,0.090616,0.079901,21:25
16,0.089492,0.082066,21:26
17,0.091471,0.079039,21:25
18,0.087618,0.078682,21:28
19,0.085892,0.075904,21:24
20,0.088187,0.083090,21:26
21,0.084222,0.077778,21:28
22,0.085597,0.079367,21:26
23,0.085086,0.074113,21:27
24,0.081812,0.074735,21:30
25,0.080433,0.075026,21:26
26,0.081008,0.074735,21:25
27,0.082539,0.073664,21:26
28,0.076719,0.072356,21:26
29,0.080298,0.071913,21:26
30,0.079734,0.071488,21:27
31,0.079510,0.070278,21:30
32,0.079232,0.071271,21:26
33,0.074716,0.069644,21:28
34,0.074762,0.069326,21:29
35,0.073686,0.069383,21:27
36,0.072719,0.069665,21:24
37,0.073841,0.068554,21:26
38,0.069992,0.067374,21:29
39,0.073458,0.067719,21:31
40,0.070433,0.067182,21:28
41,0.069425,0.068468,21:26
42,0.065729,0.066344,21:28
43,0.071603,0.066433,21:25
44,0.066025,0.066275,21:24
45,0.068558,0.066009,21:28
46,0.067213,0.065828,21:26
47,0.068784,0.065813,21:26
48,0.067204,0.065923,21:25
49,0.065775,0.066196,21:27
epoch,train_loss,valid_loss,time
0,0.084363,0.069123,27:26
1,0.083626,0.068249,27:28
2,0.075087,0.066443,27:30
3,0.074184,0.066614,27:30
4,0.078480,0.066147,27:32
5,0.075870,0.067678,27:31
6,0.080458,0.067640,27:34
7,0.076778,0.068298,27:31
8,0.078739,0.068655,27:30
