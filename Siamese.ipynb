{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sx9e_pXlCuti"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir='data'\n",
    "classes = ('person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush')\n",
    "n_epochs = 100\n",
    "emsize = 128\n",
    "batch_size1 = 16\n",
    "batch_size2 = 8\n",
    "margin = 1.\n",
    "load = None\n",
    "nc1 = 4\n",
    "ns1 = 4\n",
    "nc2 = 4\n",
    "ns2 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import os\n",
    "from data import ImageDataset\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "from networks import siamese_embedding_learner\n",
    "from data import BalancedBatchSampler, ImageEmbedList\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "import wandb\n",
    "from wandb.fastai import WandbCallback\n",
    "wandb.init(project=\"embedders-vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Image,\n",
    "    partial(crop_pad, size=512, padding_mode=\"zeros\"),\n",
    "#     transforms.Normalize(*imagenet_stats)\n",
    "])\n",
    "train_dataset = ImageDataset(\n",
    "    f\"{data_dir}/classy_coconut/train\",\n",
    "    classes,\n",
    "    tfms=tfms\n",
    ")\n",
    "val_dataset = ImageDataset(\n",
    "    f\"{data_dir}/classy_coconut/val\",\n",
    "    classes,\n",
    "    tfms=tfms\n",
    ")\n",
    "n_classes = len(classes)\n",
    "\n",
    "print(f\"Number of items in the training data set: {len(train_dataset)}\")\n",
    "print(f\"Number of items in the validation data set: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "lls = (ImageEmbedList.from_folder(f\"{data_dir}/classy_coconut\")\n",
    "       .split_by_folder(valid=\"val\")\n",
    "       .label_from_folder()\n",
    ")\n",
    "labels_train = torch.LongTensor([lls.train[i][1].data for i in range(len(lls.train))])\n",
    "labels_val = torch.LongTensor([lls.valid[i][1].data for i in range(len(lls.valid))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch, size=512, padding_mode=\"zeros\"):\n",
    "    cp = partial(crop_pad, size=size, padding_mode=padding_mode)\n",
    "    batch = [(cp(inp), lab) for inp, lab in batch]\n",
    "    return default_collate(to_data(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "dbunch = (lls\n",
    "          .transform(get_transforms())\n",
    "          .databunch(\"siamese\",\n",
    "                     bsampler=BalancedBatchSampler(labels_train, nc1, ns1),\n",
    "                     val_bsampler=BalancedBatchSampler(labels_val, nc1, ns1),\n",
    "                     collate_fn=pad_collate,\n",
    "                     device=device,\n",
    "                     num_workers=8)\n",
    "          .normalize(imagenet_stats)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "callback_fns = [\n",
    "    partial(CSVLogger, append=True),\n",
    "    partial(SaveModelCallback, every=\"improvement\", monitor=\"valid_loss\"),\n",
    "    partial(EarlyStoppingCallback, monitor=\"valid_loss\", min_delta=0.0005, patience=5),\n",
    "    partial(WandbCallback, input_type='images')\n",
    "]\n",
    "learner = siamese_embedding_learner(dbunch, models.resnet50, emsize, margin, callback_fns=callback_fns).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load is not None:\n",
    "    learner.load(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "learner.freeze()\n",
    "learner.fit_one_cycle(n_epochs, 1e-3)\n",
    "learner.save(\"embedder\")\n",
    "learner.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch = (lls\n",
    "          .transform(get_transforms())\n",
    "          .databunch(\"siamese\",\n",
    "                     bsampler=BalancedBatchSampler(labels_train, nc2, ns2),\n",
    "                     val_bsampler=BalancedBatchSampler(labels_val, nc2, ns2),\n",
    "                     collate_fn=pad_collate,\n",
    "                     device=device,\n",
    "                     num_workers=8)\n",
    "          .normalize(imagenet_stats)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = siamese_embedding_learner(dbunch, models.resnet50, emsize, margin, callback_fns=callback_fns).to_fp16()\n",
    "learner.load(\"embedder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "learner.freeze_to(1)\n",
    "learner.fit_one_cycle(n_epochs, [1e-5, 1e-4, 1e-3])\n",
    "learner.save(\"embedder\")\n",
    "learner.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = learner.validate()\n",
    "metrics_dict = {\"siamese\": {\"loss\": float(metrics[0])}}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics_dict, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "Experiments_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
